---
"@llamaindex/huggingface": patch
"@llamaindex/portkey-ai": patch
"@llamaindex/anthropic": patch
"@llamaindex/deepinfra": patch
"@llamaindex/fireworks": patch
"@llamaindex/replicate": patch
"@llamaindex/deepseek": patch
"@llamaindex/together": patch
"@llamaindex/mistral": patch
"@llamaindex/google": patch
"@llamaindex/ollama": patch
"@llamaindex/openai": patch
"@llamaindex/vercel": patch
"@llamaindex/groq": patch
"@llamaindex/vllm": patch
"@llamaindex/examples": patch
---

Add factory convenience factory for each LLM provider, e.g. you can use openai instead of 'new OpenAI'
