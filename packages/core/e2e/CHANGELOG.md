# @llamaindex/core-e2e

## 0.0.6

### Patch Changes

- 34fb1d8: fix: cloudflare dev

## 0.0.5

### Patch Changes

- c3747d0: fix: import `@xenova/transformers`

  For now, if you use llamaindex in next.js, you need to add a plugin from `llamaindex/next` to ensure some module resolutions are correct.

## 0.0.4

### Patch Changes

- be5df5b: fix: anthropic agent on multiple chat

## 0.0.3

### Patch Changes

- 61103b6: fix: streaming for `Agent.createTask` API
