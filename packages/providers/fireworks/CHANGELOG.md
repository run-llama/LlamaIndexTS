# @llamaindex/fireworks

## 0.0.12

### Patch Changes

- Updated dependencies [e5c3f95]
  - @llamaindex/openai@0.3.4

## 0.0.11

### Patch Changes

- Updated dependencies [96dd798]
  - @llamaindex/openai@0.3.3

## 0.0.10

### Patch Changes

- Updated dependencies [d365eb2]
  - @llamaindex/openai@0.3.2

## 0.0.9

### Patch Changes

- Updated dependencies [88b7046]
  - @llamaindex/openai@0.3.1

## 0.0.8

### Patch Changes

- Updated dependencies [9c63f3f]
  - @llamaindex/openai@0.3.0

## 0.0.7

### Patch Changes

- @llamaindex/openai@0.2.1

## 0.0.6

### Patch Changes

- Updated dependencies [91a18e7]
  - @llamaindex/openai@0.2.0

## 0.0.5

### Patch Changes

- Updated dependencies [a8c0637]
  - @llamaindex/openai@0.1.61

## 0.0.4

### Patch Changes

- aea550a: Add factory convenience factory for each LLM provider, e.g. you can use openai instead of 'new OpenAI'
- Updated dependencies [aea550a]
  - @llamaindex/openai@0.1.60

## 0.0.3

### Patch Changes

- @llamaindex/openai@0.1.59

## 0.0.2

### Patch Changes

- bbc8c87: fix: prefer using embedding model from vector store
