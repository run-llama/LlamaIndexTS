{
  "name": "@llamaindex/vllm",
  "description": "vLLM Adapter for LlamaIndex",
  "version": "0.0.4",
  "type": "module",
  "main": "./dist/index.cjs",
  "module": "./dist/index.js",
  "exports": {
    ".": {
      "require": {
        "types": "./dist/index.d.cts",
        "default": "./dist/index.cjs"
      },
      "import": {
        "types": "./dist/index.d.ts",
        "default": "./dist/index.js"
      }
    }
  },
  "files": [
    "dist"
  ],
  "repository": {
    "type": "git",
    "url": "https://github.com/run-llama/LlamaIndexTS.git",
    "directory": "packages/providers/vllm"
  },
  "scripts": {
    "build": "bunchee",
    "dev": "bunchee --watch"
  },
  "devDependencies": {
    "bunchee": "5.6.1"
  },
  "dependencies": {
    "@llamaindex/openai": "workspace:*"
  }
}
