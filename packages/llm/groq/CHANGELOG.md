# @llamaindex/groq

## 0.0.16

### Patch Changes

- @llamaindex/openai@0.1.17

## 0.0.15

### Patch Changes

- Updated dependencies [6a9a7b1]
  - @llamaindex/openai@0.1.16

## 0.0.14

### Patch Changes

- @llamaindex/openai@0.1.15

## 0.0.13

### Patch Changes

- @llamaindex/openai@0.1.14

## 0.0.12

### Patch Changes

- @llamaindex/openai@0.1.13

## 0.0.11

### Patch Changes

- 2a82413: fix(core): set `Settings.llm` to OpenAI by default and support lazy load openai
- Updated dependencies [2a82413]
  - @llamaindex/openai@0.1.12

## 0.0.10

### Patch Changes

- @llamaindex/openai@0.1.11

## 0.0.9

### Patch Changes

- Updated dependencies [df441e2]
  - @llamaindex/env@0.1.13
  - @llamaindex/openai@0.1.10

## 0.0.8

### Patch Changes

- Updated dependencies [96f72ad]
  - @llamaindex/openai@0.1.9

## 0.0.7

### Patch Changes

- @llamaindex/openai@0.1.8

## 0.0.6

### Patch Changes

- @llamaindex/openai@0.1.7

## 0.0.5

### Patch Changes

- Updated dependencies [b48bcc3]
  - @llamaindex/env@0.1.12
  - @llamaindex/openai@0.1.6

## 0.0.4

### Patch Changes

- @llamaindex/openai@0.1.5

## 0.0.3

### Patch Changes

- @llamaindex/openai@0.1.4

## 0.0.2

### Patch Changes

- fbd5e01: refactor: move groq as llm package
- Updated dependencies [ac07e3c]
- Updated dependencies [1a6137b]
- Updated dependencies [ac07e3c]
  - @llamaindex/env@0.1.11
  - @llamaindex/openai@0.1.3
