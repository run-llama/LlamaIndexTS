---
title: With TypeScript
description: In this guide, you'll learn how to use LlamaIndex with TypeScript
---
import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

LlamaIndex.TS is written in TypeScript and designed to be used in TypeScript projects.

We do lots of work on strong typing to make sure you have a great typing experience with LlamaIndex.TS.

```ts twoslash
import { PromptTemplate } from '@llamaindex/core/prompts'
const promptTemplate = new PromptTemplate({
  template: `Context information from multiple sources is below.
---------------------
{context}
---------------------
Given the information from multiple sources and not prior knowledge.
Answer the query in the style of a Shakespeare play"
Query: {query}
Answer:`,
	templateVars: ["context", "query"],
});
// @noErrors
promptTemplate.format({
	c
//^|
})
```

```ts twoslash
import { FunctionTool } from '@llamaindex/core/tools'
import { z } from 'zod'

// ---cut-before---
const inputSchema = z.object({
	time: z.string(),
	city: z.string(),
})

type Input = z.infer<typeof inputSchema>

FunctionTool.from<Input>((input) => {
// @noErrors
	input.t
//      ^|
}, {
	name: 'getWeather',
	description: 'Get the weather information',
	parameters: inputSchema,
})
```

## Enable TypeScript


```json5
{
  compilerOptions: {
    // ⬇️ add this line to your tsconfig.json
    moduleResolution: "bundler", // or "node16"
  },
}
```

<Accordions>
	<Accordion
		title="Why modify tsconfig.json"
	>

We are shipping both ESM and CJS module, and compatible with Vercel Edge, Cloudflare Workers, and other serverless platforms.

So we are using [conditional exports](https://nodejs.org/api/packages.html#conditional-exports) to support all environments.

This is a kind of modern way of shipping packages, but might cause TypeScript type check to fail because of legacy module resolution.

Imaging you put output file into `/dist/openai.js` but you are importing `llamaindex/openai` in your code, and set `package.json` like this:

```json5
{
	"exports": {
		"./openai": "./dist/openai.js"
	}
}
```

In old module resolution, TypeScript will not be able to find the module because it is not follow the file structure, even you run `node index.js` successfully. (on Node.js >=16)

See more about [moduleResolution](https://www.typescriptlang.org/docs/handbook/modules/theory.html#module-resolution) or
[TypeScript 5.0 blog](https://devblogs.microsoft.com/typescript/announcing-typescript-5-0/#--moduleresolution-bundler7).


	</Accordion>
</Accordions>

## Enable AsyncIterable for `Web Stream` API

Some modules uses `Web Stream` API like `ReadableStream` and `WritableStream`, you need to enable `DOM.AsyncIterable` in your `tsconfig.json`.

```json5
{
  compilerOptions: {
    // ⬇️ add this lib to your tsconfig.json
    lib: ["DOM.AsyncIterable"],
  },
}
```

```ts twoslash
import { OpenAIAgent } from '@llamaindex/openai'

const agent = new OpenAIAgent({
  tools: []
})

const response = await agent.chat({
  message: 'Hello, how are you?',
  stream: true
})
for await (const _ of response) {
                      //^?
  // ...
}
```

## Run TypeScript Script in Node.js

We recommend to use [tsx](https://www.npmjs.com/package/tsx) to run TypeScript script in Node.js.

```shell
node --import tsx ./my-script.ts
```
