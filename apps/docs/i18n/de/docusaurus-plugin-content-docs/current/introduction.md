---
sidebar_position: 0
slug: /
---

# Was ist LlamaIndex.TS?

`Diese Dokumentation wurde automatisch √ºbersetzt und kann Fehler enthalten. Z√∂gern Sie nicht, einen Pull Request zu √∂ffnen, um √Ñnderungen vorzuschlagen.`

LlamaIndex.TS ist ein Datenframework f√ºr LLM-Anwendungen zum Aufnehmen, Strukturieren und Zugreifen auf private oder dom√§nenspezifische Daten. W√§hrend auch ein Python-Paket verf√ºgbar ist (siehe [hier](https://docs.llamaindex.ai/en/stable/)), bietet LlamaIndex.TS Kernfunktionen in einem einfachen Paket, das f√ºr die Verwendung mit TypeScript optimiert ist.

## üöÄ Warum LlamaIndex.TS?

Im Kern bieten LLMs eine nat√ºrliche Sprachschnittstelle zwischen Menschen und abgeleiteten Daten. Weit verbreitete Modelle sind vortrainiert auf riesigen Mengen √∂ffentlich verf√ºgbarer Daten, von Wikipedia und Mailinglisten bis hin zu Lehrb√ºchern und Quellcode.

Anwendungen, die auf LLMs aufbauen, erfordern oft die Erg√§nzung dieser Modelle um private oder dom√§nenspezifische Daten. Leider k√∂nnen diese Daten √ºber verschiedene Anwendungen und Datenspeicher verteilt sein. Sie befinden sich hinter APIs, in SQL-Datenbanken oder sind in PDFs und Pr√§sentationen gefangen.

Genau hier kommt **LlamaIndex.TS** ins Spiel.

## ü¶ô Wie kann LlamaIndex.TS helfen?

LlamaIndex.TS bietet folgende Tools:

- **Datenladen** - Importieren Sie Ihre vorhandenen `.txt`, `.pdf`, `.csv`, `.md` und `.docx` Daten direkt.
- **Datenindizes** - Strukturieren Sie Ihre Daten in Zwischenrepr√§sentationen, die f√ºr LLMs einfach und leistungsstark zu verarbeiten sind.
- **Engines** - Bieten Sie einen nat√ºrlichsprachlichen Zugriff auf Ihre Daten. Zum Beispiel:
  - Abfrage-Engines sind leistungsstarke Abfrage-Schnittstellen f√ºr wissensgest√ºtzte Ausgaben.
  - Chat-Engines sind konversationelle Schnittstellen f√ºr Interaktionen mit Ihren Daten, bei denen mehrere Nachrichten hin und her ausgetauscht werden.

## üë®‚Äçüë©‚Äçüëß‚Äçüë¶ F√ºr wen ist LlamaIndex?

LlamaIndex.TS bietet einen Kernsatz von Tools, die f√ºr alle geeignet sind, die LLM-Apps mit JavaScript und TypeScript entwickeln.

Unsere API auf hoher Ebene erm√∂glicht es Anf√§ngern, LlamaIndex.TS zum Aufnehmen und Abfragen ihrer Daten zu verwenden.

F√ºr komplexere Anwendungen erm√∂glichen unsere APIs auf niedrigerer Ebene fortgeschrittenen Benutzern, jedes Modul - Datenverbindungen, Indizes, Retriever und Abfrage-Engines - anzupassen und zu erweitern, um ihren Anforderungen gerecht zu werden.

## Erste Schritte

`npm install llamaindex`

Unsere Dokumentation enth√§lt [Installationsanweisungen](./installation.mdx) und ein [Einf√ºhrungstutorial](./starter.md), um Ihre erste Anwendung zu erstellen.

Sobald Sie bereit sind, bietet [High-Level-Konzepte](./concepts.md) einen √úberblick √ºber die modulare Architektur von LlamaIndex. F√ºr praktische Beispiele schauen Sie sich unsere [End-to-End-Tutorials](./end_to_end.md) an.

## üó∫Ô∏è √ñkosystem

Um LlamaIndex herunterzuladen oder beizutragen, finden Sie es auf:

- Github: https://github.com/run-llama/LlamaIndexTS
- NPM: https://www.npmjs.com/package/llamaindex

"

## Community

Brauchen Sie Hilfe? Haben Sie einen Funktionsvorschlag? Treten Sie der LlamaIndex-Community bei:

- Twitter: https://twitter.com/llama_index
- Discord: https://discord.gg/dGcwcsnxhU
