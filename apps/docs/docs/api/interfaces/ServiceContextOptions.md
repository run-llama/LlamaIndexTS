---
id: "ServiceContextOptions"
title: "Interface: ServiceContextOptions"
sidebar_label: "ServiceContextOptions"
sidebar_position: 0
custom_edit_url: null
---

## Properties

### callbackManager

• `Optional` **callbackManager**: [`CallbackManager`](../classes/CallbackManager.md)

#### Defined in

[ServiceContext.ts:26](https://github.com/run-llama/LlamaIndexTS/blob/d73ac8e/packages/core/src/ServiceContext.ts#L26)

___

### chunkOverlap

• `Optional` **chunkOverlap**: `number`

#### Defined in

[ServiceContext.ts:29](https://github.com/run-llama/LlamaIndexTS/blob/d73ac8e/packages/core/src/ServiceContext.ts#L29)

___

### chunkSize

• `Optional` **chunkSize**: `number`

#### Defined in

[ServiceContext.ts:28](https://github.com/run-llama/LlamaIndexTS/blob/d73ac8e/packages/core/src/ServiceContext.ts#L28)

___

### embedModel

• `Optional` **embedModel**: [`BaseEmbedding`](../classes/BaseEmbedding.md)

#### Defined in

[ServiceContext.ts:24](https://github.com/run-llama/LlamaIndexTS/blob/d73ac8e/packages/core/src/ServiceContext.ts#L24)

___

### llm

• `Optional` **llm**: [`OpenAI`](../classes/OpenAI.md)

#### Defined in

[ServiceContext.ts:22](https://github.com/run-llama/LlamaIndexTS/blob/d73ac8e/packages/core/src/ServiceContext.ts#L22)

___

### llmPredictor

• `Optional` **llmPredictor**: [`BaseLLMPredictor`](BaseLLMPredictor.md)

#### Defined in

[ServiceContext.ts:21](https://github.com/run-llama/LlamaIndexTS/blob/d73ac8e/packages/core/src/ServiceContext.ts#L21)

___

### nodeParser

• `Optional` **nodeParser**: [`NodeParser`](NodeParser.md)

#### Defined in

[ServiceContext.ts:25](https://github.com/run-llama/LlamaIndexTS/blob/d73ac8e/packages/core/src/ServiceContext.ts#L25)

___

### promptHelper

• `Optional` **promptHelper**: `PromptHelper`

#### Defined in

[ServiceContext.ts:23](https://github.com/run-llama/LlamaIndexTS/blob/d73ac8e/packages/core/src/ServiceContext.ts#L23)
